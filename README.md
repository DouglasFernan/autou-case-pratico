# AutoU - Case PrÃ¡tico: Classificador de Emails com IA ğŸš€

> **Aviso:** Esta Ã© uma aplicaÃ§Ã£o de demonstraÃ§Ã£o que utiliza a API do Google Gemini. O uso Ã© moderado para garantir que a aplicaÃ§Ã£o permaneÃ§a funcional para o processo de avaliaÃ§Ã£o. ğŸ˜Š

---

### ğŸ¥ DemonstraÃ§Ã£o RÃ¡pida

![DemonstraÃ§Ã£o da AplicaÃ§Ã£o](./assets/demonstracao.gif)

_DemonstraÃ§Ã£o do fluxo de anÃ¡lise de um email, exibindo a classificaÃ§Ã£o e a sugestÃ£o de resposta._

---

## âœ… VisÃ£o Geral e Funcionalidades

Este projeto Ã© uma soluÃ§Ã£o completa para o Case PrÃ¡tico de Desenvolvimento da AutoU. Trata-se de uma aplicaÃ§Ã£o web full-stack que utiliza InteligÃªncia Artificial para analisar, classificar e gerar respostas para emails, otimizando a produtividade de equipes.

- **ClassificaÃ§Ã£o Inteligente:** Identifica se um email requer uma aÃ§Ã£o (`Produtivo`) ou nÃ£o (`Improdutivo`).
- **Respostas AutomÃ¡ticas:** Gera sugestÃµes de respostas contextuais e com formataÃ§Ã£o profissional.
- **MÃºltiplos Formatos de Entrada:** Permite a anÃ¡lise de texto colado diretamente ou atravÃ©s do upload de arquivos `.txt` e `.pdf`.
- **Interface Reativa e Intuitiva:** ExperiÃªncia de usuÃ¡rio fluida, com feedback visual claro (loading, sucesso, erro).
- **Funcionalidades de UX:** Inclui recursos pensados no usuÃ¡rio, como "Copiar Resposta" e "Ver Email Enviado".

---

## âš™ï¸ Tecnologias Utilizadas

- **Frontend:** React, Next.js, TypeScript, Tailwind CSS
- **Backend:** Python, FastAPI
- **IA & Cloud:** Google Gemini, Vercel (Frontend), Render (Backend)

---

## ğŸ”§ Como Rodar o Projeto Localmente

### PrÃ©-requisitos

- [Node.js](https://nodejs.org/en/) (v18+)
- [Python](https://www.python.org/downloads/) (v3.9+)
- Uma chave de API vÃ¡lida do [Google Gemini](https://aistudio.google.com/)

### Passos para a InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**

   ```bash
   git clone https://github.com/DouglasFernan/autou-case-pratico.git
   cd autou-case-pratico
   ```

2. **Configure o Backend:**

   ```bash
   cd backend
   python -m venv venv
   source venv/bin/activate  # No Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

   Crie o arquivo `.env` na pasta `backend/` e adicione sua chave:

   ```env
   GOOGLE_API_KEY="SUA_CHAVE_SECRETA_DO_GEMINI_AQUI"
   ```

   > ğŸ’¡ **ObservaÃ§Ã£o:** Em alguns ambientes locais, o carregamento do arquivo `.env` pode ser instÃ¡vel. Caso enfrente um erro de credenciais, uma alternativa para teste Ã© inserir a chave de API diretamente no cÃ³digo (`gemini_service.py`), lembrando de **NÃƒO** enviar esta alteraÃ§Ã£o para o GitHub.  
   > A versÃ£o em produÃ§Ã£o no Render utiliza as variÃ¡veis de ambiente de forma segura.

3. **Configure o Frontend:**

   ```bash
   cd ../frontend
   npm install
   ```

4. **Execute a AplicaÃ§Ã£o (em 2 terminais separados):**

   - **Terminal 1 (backend):**

     ```bash
     cd backend
     uvicorn app.main:app --reload
     ```

   - **Terminal 2 (frontend):**
     ```bash
     cd frontend
     npm run dev
     ```

   Acesse o frontend em: [http://localhost:3000](http://localhost:3000)

---

## ğŸ“‚ Dados de Exemplo

Para facilitar os testes, uma variedade de arquivos de exemplo (`.txt` e `.pdf`) com conteÃºdo produtivo e improdutivo pode ser encontrada na pasta [`assets/exemplos/`](./assets/exemplos/) deste repositÃ³rio.

---

## ğŸ’¡ DecisÃµes TÃ©cnicas e Arquitetura

- **Uso de LLM vs. NLP ClÃ¡ssico:** Optei por utilizar um Large Language Model (Gemini) em vez de tÃ©cnicas de NLP tradicionais. Esta foi uma escolha tÃ©cnica deliberada, pois LLMs entendem o contexto completo do texto, e o prÃ©-processamento manual prejudicaria a precisÃ£o da anÃ¡lise.
- **Engenharia de Prompt:** O "treinamento" e "ajuste" da IA foram realizados via engenharia de prompt, utilizando a tÃ©cnica de "few-shot learning", fornecendo ao modelo exemplos claros para garantir alta precisÃ£o.
- **Arquitetura Desacoplada:** A escolha de separar Frontend (Next.js) e Backend (FastAPI) cria uma soluÃ§Ã£o mais escalÃ¡vel e manutenÃ­vel.

---

## ğŸ—ºï¸ VisÃ£o do Produto e PrÃ³ximos Passos

Esta aplicaÃ§Ã£o serve como uma robusta Prova de Conceito (PoC). Para evoluir para uma soluÃ§Ã£o completa, os prÃ³ximos passos seriam:

- **IntegraÃ§Ã£o Direta com Provedores de Email:** Conectar a aplicaÃ§Ã£o via API (Google, Microsoft) para ingerir emails automaticamente.
- **Processamento AssÃ­ncrono:** Implementar uma fila de tarefas (com Celery e Redis) para analisar emails em segundo plano.
- **Dashboard de Triagem:** Transformar a interface em um dashboard completo com filtros e aÃ§Ãµes em massa.

---

## ğŸ‘¤ Autor

- **Nome:** Douglas Fernandes Soares Bessa
- **LinkedIn:** https://www.linkedin.com/in/dougfernan/
- **GitHub:** https://github.com/DouglasFernan

---

## âš ï¸ LimitaÃ§Ã£o da Hospedagem

> **ObservaÃ§Ã£o:** Como o backend estÃ¡ hospedado no Render (plano gratuito), a aplicaÃ§Ã£o pode apresentar uma **lentidÃ£o na primeira requisiÃ§Ã£o** apÃ³s um perÃ­odo de inatividade.  
> Isso acontece porque o servidor "hiberna" quando nÃ£o estÃ¡ em uso e precisa ser reiniciado ao receber uma nova requisiÃ§Ã£o.  
> ApÃ³s esse aquecimento inicial, as respostas voltam a ser rÃ¡pidas e estÃ¡veis.
